{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In an earlier mission, we learned about train/test validation, a simple technique for testing a machine learning model's accuracy on new data that the model wasn't trained on. In this mission, we'll focus on more robust techniques.\n",
    "\n",
    "To start, we'll focus on the holdout validation technique, which involves:\n",
    "\n",
    "splitting the full dataset into 2 partitions:\n",
    "a training set\n",
    "a test set\n",
    "training the model on the training set,\n",
    "using the trained model to predict labels on the test set,\n",
    "computing an error metric to understand the model's effectiveness,\n",
    "switch the training and test sets and repeat,\n",
    "average the errors.\n",
    "In holdout validation, we usually use a 50/50 split instead of the 75/25 split from train/test validation. This way, we remove number of observations as a potential source of variation in our model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "dc_listings = pd.read_csv(\"data/dc_airbnb.csv\")\n",
    "dc_listings['price'] = dc_listings['price'].str.replace('[,|$]', '').astype('float')\n",
    "\n",
    "# Use the numpy.random.permutation() function to shuffle the ordering of the rows in dc_listings.\n",
    "randomized_index = np.random.permutation(dc_listings.index)\n",
    "# Select the first 1862 rows and assign to split_one.\n",
    "split_one = dc_listings.loc[randomized_index[:1862]]\n",
    "# Select the remaining 1861 rows and assign to split_two.\n",
    "split_two = dc_listings.loc[randomized_index[1862:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_one = split_one\n",
    "test_one = split_two\n",
    "train_two = split_two\n",
    "test_two = split_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127.90266516816538, 138.6984822541034, 133.3005737111344)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train a k-nearest neighbors model using the default algorithm (auto) and the default number of neighbors (5) that:\n",
    "# Uses the accommodates column from train_one for training and\n",
    "# Tests it on test_one.`\n",
    "# Assign the resulting RMSE value to iteration_one_rmse.\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(train_one[['accommodates']], train_one['price'])\n",
    "predictions = knn.predict(test_one[['accommodates']])\n",
    "iteration_one_rmse = mean_squared_error(test_one['price'], predictions) ** (0.5)\n",
    "# Train a k-nearest neighbors model using the default algorithm (auto) and the default number of neighbors (5) that:\n",
    "# Uses the accommodates column from train_two for training and\n",
    "# Tests it on test_two.\n",
    "# Assign the resulting RMSE value to iteration_two_rmse.\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(train_two[['accommodates']], train_two['price'])\n",
    "predictions = knn.predict(test_two[['accommodates']])\n",
    "iteration_two_rmse = mean_squared_error(test_two['price'], predictions) ** (0.5)\n",
    "# Use numpy.mean() to calculate the average of the 2 RMSE values and assign to avg_rmse.\n",
    "avg_rmse = np.mean((iteration_one_rmse, iteration_two_rmse))\n",
    "iteration_one_rmse, iteration_two_rmse, avg_rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we average the two RMSE values from the last step, we get an RMSE value of approximately 133.30. Holdout validation is actually a specific example of a larger class of validation techniques called k-fold cross-validation. While holdout validation is better than train/test validation because the model isn't repeatedly biased towards a specific subset of the data, both models that are trained only use half the available data. K-fold cross validation, on the other hand, takes advantage of a larger proportion of the data during training while still rotating through different subsets of the data to avoid the issues of train/test validation.\n",
    "\n",
    "Here's the algorithm from k-fold cross validation:\n",
    "\n",
    "splitting the full dataset into k equal length partitions,\n",
    "selecting k-1 partitions as the training set and\n",
    "selecting the remaining partition as the test set\n",
    "training the model on the training set,\n",
    "using the trained model to predict labels on the test fold,\n",
    "computing the test fold's error metric,\n",
    "repeating all of the above steps k-1 times, until each partition has been used as the test set for an iteration,\n",
    "calculating the mean of the k error values.\n",
    "Holdout validation is essentially a version of k-fold cross validation when k is equal to 2. Generally, 5 or 10 folds is used for k-fold cross-validation. Here's a diagram describing each iteration of 5-fold cross validation:\n",
    "\n",
    "\n",
    "As you increase the number the folds, the number of observations in each fold decreases and the variance of the fold-by-fold errors increases. Let's start by manually partitioning the data set into 5 folds. Instead of splitting into 5 dataframes, let's add a column that specifies which fold the row belongs to. This way, we can easily select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new column to dc_listings named fold that contains the fold number each row belongs to:\n",
    "# Fold 1 should have rows from index 0 to 744, including both of those rows.\n",
    "# Fold 2 should have rows from index 744 to 1488, including both of those rows.\n",
    "# Fold 3 should have rows from index 1488 to 2232, including both of those rows.\n",
    "# Fold 4 should have rows from index 2232 to 2976, including both of those rows.\n",
    "# Fold 5 should have rows from index 2976 to 3723, including both of these rows.\n",
    "# Display the unique value counts for the fold column to confirm that each fold has roughly the same number of elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    747\n",
       "3    744\n",
       "1    744\n",
       "4    744\n",
       "2    744\n",
       "Name: fold, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folds = dc_listings.index // 744\n",
    "dc_listings['fold'] = np.where(folds < 5, folds + 1, 5)\n",
    "dc_listings.fold.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a k-nearest neighbors model using the accommodates column as the sole feature from folds 2 to 5 as the training set.\n",
    "# Use the model to make predictions on the test set (accommodates column from fold 1) and assign the predicted labels to labels.\n",
    "# Calculate the RMSE value by comparing the price column with the predicted labels.\n",
    "# Assign the RMSE value to iteration_one_rmse.\n",
    "train_df = dc_listings.loc[dc_listings['fold'] > 1]\n",
    "test_df = dc_listings.loc[dc_listings['fold'] == 1]\n",
    "knn = KNeighborsRegressor()\n",
    "knn.fit(train_df[['accommodates']], train_df['price'])\n",
    "labels = knn.predict(test_df[['accommodates']])\n",
    "iteration_one_rmse = mean_squared_error(test_df['price'], labels) ** (0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([137.26488167749056,\n",
       "  99.71116620853789,\n",
       "  163.72074818756715,\n",
       "  116.12777422406992,\n",
       "  157.38717103508057],\n",
       " 134.8423482665492)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Write a function named train_and_validate that takes in a dataframe as the first parameter (df) and a list of fold values (1 to 5 in our case) as the second parameter (folds). This function should:\n",
    "\n",
    "# Train n models (where n is number of folds) and perform k-fold cross validation (using n folds). Use the default k value for the KNeighborsRegressor class.\n",
    "# Return a list of RMSE values, where the first element is the RMSE for when fold 1 was the test set, the second element is the RMSE for when fold 2 was the test set, and so on.\n",
    "def train_and_validate(df, folds):\n",
    "    rmse_results = []\n",
    "    for n in folds:\n",
    "        test_df = df[df['fold'] == n]\n",
    "        train_df = df[df['fold'] != n]\n",
    "        knn = KNeighborsRegressor()\n",
    "        knn.fit(train_df[['accommodates']], train_df['price'])\n",
    "        labels = knn.predict(test_df[['accommodates']])\n",
    "        rmse = mean_squared_error(test_df['price'], labels) ** (0.5)\n",
    "        rmse_results.append(rmse)\n",
    "    return rmse_results\n",
    "\n",
    "# Use the train_and_validate function to return the list of RMSE values for the dc_listings Dataframe and assign to rmses.\n",
    "rmses = train_and_validate(dc_listings, range(1,6))\n",
    "# Calculate the mean of these values and assign to avg_rmse.\n",
    "avg_rmse = np.mean(rmses)\n",
    "# Display both rmses and avg_rmse.\n",
    "rmses, avg_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new instance of the KFold class with the following properties:\n",
    "\n",
    "# 5 folds,\n",
    "# shuffle set to True,\n",
    "# random seed set to 1 (so we can answer check using the same seed),\n",
    "# assigned to the variable kf.\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# Create a new instance of the KNeighborsRegressor class and assign to knn.\n",
    "knn = KNeighborsRegressor()\n",
    "# Use the cross_val_score() function to perform k-fold cross-validation:\n",
    "\n",
    "# using the KNeighborsRegressor instance knn,\n",
    "# using the accommodates column for training,\n",
    "# using the price column as the target column,\n",
    "# returning an array of MSE values (one value for each fold).\n",
    "# Assign the resulting list of MSE values to mses.\n",
    "mses = cross_val_score(knn, dc_listings[['accommodates']], dc_listings['price'], cv=kf,\n",
    "                      scoring='neg_mean_squared_error')\n",
    "# Then, take the absolute value followed by the square root of each mse value.\n",
    "# Then, calculate the average of the resulting RMSE values and assign to avg_rmse.\n",
    "avg_rmse = np.mean(np.sqrt(np.abs(mses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 folds:  avg RMSE:  127.19146799819767 std RMSE:  7.80114274447321\n",
      "5 folds:  avg RMSE:  130.57004998596955 std RMSE:  15.968993082617418\n",
      "7 folds:  avg RMSE:  124.74000565490935 std RMSE:  23.009326104623764\n",
      "9 folds:  avg RMSE:  133.85427296864364 std RMSE:  20.275996691809862\n",
      "10 folds:  avg RMSE:  134.50358073016668 std RMSE:  30.83892745302988\n",
      "11 folds:  avg RMSE:  129.58548991863123 std RMSE:  22.39316430178567\n",
      "13 folds:  avg RMSE:  133.05101345639838 std RMSE:  27.88932598342725\n",
      "15 folds:  avg RMSE:  124.86715246014936 std RMSE:  37.03384132069149\n",
      "17 folds:  avg RMSE:  131.3786960290144 std RMSE:  40.043451719093724\n",
      "19 folds:  avg RMSE:  129.0143524209374 std RMSE:  44.3383982741942\n",
      "21 folds:  avg RMSE:  125.49498964946545 std RMSE:  41.03033829748872\n",
      "23 folds:  avg RMSE:  125.27939162120605 std RMSE:  41.668089858618046\n"
     ]
    }
   ],
   "source": [
    "num_folds = [3, 5, 7, 9, 10, 11, 13, 15, 17, 19, 21, 23]\n",
    "\n",
    "for fold in num_folds:\n",
    "    kf = KFold(fold, shuffle=True, random_state=1)\n",
    "    model = KNeighborsRegressor()\n",
    "    mses = cross_val_score(model, dc_listings[[\"accommodates\"]], dc_listings[\"price\"], scoring=\"neg_mean_squared_error\", cv=kf)\n",
    "    rmses = np.sqrt(np.absolute(mses))\n",
    "    avg_rmse = np.mean(rmses)\n",
    "    std_rmse = np.std(rmses)\n",
    "    print(str(fold), \"folds: \", \"avg RMSE: \", str(avg_rmse), \"std RMSE: \", str(std_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
